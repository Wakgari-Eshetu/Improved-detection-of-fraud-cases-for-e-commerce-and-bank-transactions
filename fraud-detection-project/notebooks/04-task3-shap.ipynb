{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a8414dc",
   "metadata": {},
   "source": [
    "# 1) Import required libraries\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from IPython.display import IFrame, HTML, display\n",
    "\n",
    "import joblib\n",
    "import shap\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Project util\n",
    "from src.explainability.shap_explainer import SHAPExplainer\n",
    "\n",
    "# Notebook display settings\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid')\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cffcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Constants and configuration\n",
    "\n",
    "DATA_PATH = Path(os.getenv('FRAUD_PROCESSED', 'data/processed/Fraud_Data_processed.csv'))\n",
    "MODEL_PATH = Path(os.getenv('FRAUD_MODEL', 'modelsave/best_model.joblib'))\n",
    "OUTPUT_DIR = Path(os.getenv('EXPLAIN_OUTPUT', 'outputs/explainability'))\n",
    "TARGET_COL = 'class'\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "Path('modelsave').mkdir(parents=True, exist_ok=True)\n",
    "Path('docs').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"DATA_PATH={DATA_PATH}, MODEL_PATH={MODEL_PATH}, OUTPUT_DIR={OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cef6949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Load and preprocess data (with fallback to small synthetic sample)\n",
    "\n",
    "if DATA_PATH.exists():\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print('Loaded processed data:', df.shape)\n",
    "else:\n",
    "    print('Processed data not found; creating a small synthetic dataset for demo')\n",
    "    rng = np.random.RandomState(42)\n",
    "    size = 2000\n",
    "    df = pd.DataFrame({\n",
    "        'amount': np.abs(rng.normal(100, 50, size)),\n",
    "        'time_since_signup_h': rng.exponential(scale=24, size=size),\n",
    "        'device_is_new': rng.randint(0, 2, size=size),\n",
    "        'ip_risk_score': rng.uniform(0, 1, size),\n",
    "        'transaction_hour': rng.randint(0, 24, size=size),\n",
    "        'class': (rng.rand(size) < 0.05).astype(int)\n",
    "    })\n",
    "\n",
    "assert TARGET_COL in df.columns, f\"Target column '{TARGET_COL}' not present\"\n",
    "\n",
    "# Small preprocessing: drop rows with missing target, sample for speed\n",
    "df = df.dropna(subset=[TARGET_COL])\n",
    "if len(df) > 5000:\n",
    "    df = df.sample(5000, random_state=42)\n",
    "\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print('Train/Test shapes:', X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5141a77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Load or train model\n",
    "\n",
    "if MODEL_PATH.exists():\n",
    "    print('Loading model from', MODEL_PATH)\n",
    "    model = joblib.load(MODEL_PATH)\n",
    "else:\n",
    "    print('Model not found; training a small XGBoost model for this notebook')\n",
    "    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, n_jobs=4)\n",
    "    model.fit(X_train, y_train)\n",
    "    joblib.dump(model, MODEL_PATH)\n",
    "    print('Saved model to', MODEL_PATH)\n",
    "\n",
    "# Feature names\n",
    "feature_names = list(X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dd86fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Built-in feature importance (top 10)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if hasattr(model, 'feature_importances_'):\n",
    "    importances = model.feature_importances_\n",
    "elif hasattr(model, 'coef_'):\n",
    "    importances = np.abs(model.coef_).ravel()\n",
    "else:\n",
    "    importances = None\n",
    "\n",
    "if importances is not None:\n",
    "    idx = np.argsort(importances)[::-1]\n",
    "    top_idx = idx[:10]\n",
    "    top_feats = [feature_names[i] for i in top_idx]\n",
    "    top_vals = importances[top_idx]\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.barh(range(len(top_feats)), top_vals[::-1])\n",
    "    plt.yticks(range(len(top_feats)), top_feats[::-1])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Top 10 Feature Importances')\n",
    "    plt.tight_layout()\n",
    "    fp = OUTPUT_DIR / 'feature_importance_top10.png'\n",
    "    plt.savefig(fp, dpi=150)\n",
    "    plt.show()\n",
    "    print('Saved feature importance to', fp)\n",
    "else:\n",
    "    print('Model does not expose importances')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559006b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) SHAP analysis: compute and save summary plot\n",
    "\n",
    "expl = SHAPExplainer(model, feature_names)\n",
    "\n",
    "# Use a subset for speed in notebooks\n",
    "X_shap = X_test.copy()\n",
    "if len(X_shap) > 2000:\n",
    "    X_shap = X_shap.sample(2000, random_state=42)\n",
    "\n",
    "start = time.perf_counter()\n",
    "shap_values = expl.explain(X_shap)\n",
    "end = time.perf_counter()\n",
    "print(f\"Computed SHAP values for {len(X_shap)} rows in {end-start:.2f}s\")\n",
    "\n",
    "# Save summary plot\n",
    "summary_fp = OUTPUT_DIR / 'shap_summary.png'\n",
    "expl.plot_summary_save(shap_values, X_shap, str(summary_fp))\n",
    "print('Saved SHAP summary to', summary_fp)\n",
    "\n",
    "# Display summary inline\n",
    "from IPython.display import Image\n",
    "display(Image(str(summary_fp)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d322beeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Identify TP, FP, FN examples and show rows\n",
    "\n",
    "probs = model.predict_proba(X_test)[:,1]\n",
    "preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "# convert y_test to aligned index\n",
    "y_test_aligned = y_test.reset_index(drop=True)\n",
    "\n",
    "def find_index(condition):\n",
    "    for i in range(len(y_test_aligned)):\n",
    "        if condition(i):\n",
    "            return i\n",
    "    return None\n",
    "\n",
    "idx_tp = find_index(lambda i: y_test_aligned[i] == 1 and preds[i] == 1)\n",
    "idx_fp = find_index(lambda i: y_test_aligned[i] == 0 and preds[i] == 1)\n",
    "idx_fn = find_index(lambda i: y_test_aligned[i] == 1 and preds[i] == 0)\n",
    "\n",
    "print('Indices found - TP:', idx_tp, 'FP:', idx_fp, 'FN:', idx_fn)\n",
    "\n",
    "if idx_tp is not None:\n",
    "    display(X_test.reset_index(drop=True).iloc[idx_tp])\n",
    "if idx_fp is not None:\n",
    "    display(X_test.reset_index(drop=True).iloc[idx_fp])\n",
    "if idx_fn is not None:\n",
    "    display(X_test.reset_index(drop=True).iloc[idx_fn])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bbffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Force plots for selected examples (saved as HTML)\n",
    "\n",
    "if idx_tp is not None:\n",
    "    fp_tp = OUTPUT_DIR / 'shap_force_tp.html'\n",
    "    expl.plot_force_save(shap_values, X_shap.reset_index(drop=True), idx_tp, str(fp_tp))\n",
    "    display(HTML(f\"<a href='{fp_tp}' target='_blank'>Open TP force plot</a>\"))\n",
    "\n",
    "if idx_fp is not None:\n",
    "    fp_fp = OUTPUT_DIR / 'shap_force_fp.html'\n",
    "    expl.plot_force_save(shap_values, X_shap.reset_index(drop=True), idx_fp, str(fp_fp))\n",
    "    display(HTML(f\"<a href='{fp_fp}' target='_blank'>Open FP force plot</a>\"))\n",
    "\n",
    "if idx_fn is not None:\n",
    "    fp_fn = OUTPUT_DIR / 'shap_force_fn.html'\n",
    "    expl.plot_force_save(shap_values, X_shap.reset_index(drop=True), idx_fn, str(fp_fn))\n",
    "    display(HTML(f\"<a href='{fp_fn}' target='_blank'>Open FN force plot</a>\"))\n",
    "\n",
    "print('Saved force plot files to', OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133e1086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Top drivers and short interpretation\n",
    "\n",
    "mean_abs_shap = np.mean(np.abs(shap_values), axis=0)\n",
    "order = np.argsort(mean_abs_shap)[::-1]\n",
    "\n",
    "top5_idx = order[:5]\n",
    "pd.DataFrame({\n",
    "    'feature': [feature_names[i] for i in top5_idx],\n",
    "    'mean_abs_shap': mean_abs_shap[top5_idx]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b444dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) Simple unit tests (inline)\n",
    "\n",
    "def _test_shap_small_flow():\n",
    "    # sanity: SHAP explainer runs on small subset\n",
    "    small_X = X_train.head(50)\n",
    "    expl_local = SHAPExplainer(model, feature_names)\n",
    "    shap_vals_local = expl_local.explain(small_X)\n",
    "    assert shap_vals_local.shape[0] == small_X.shape[0]\n",
    "    assert shap_vals_local.shape[1] == small_X.shape[1]\n",
    "\n",
    "print('Running quick inline test...')\n",
    "_test_shap_small_flow()\n",
    "print('Inline tests passed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df15519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11) Save outputs and provide quick run instructions\n",
    "\n",
    "# Save top 5 drivers to CSV\n",
    "drivers_fp = OUTPUT_DIR / 'top5_shap_drivers.csv'\n",
    "pd.DataFrame({\n",
    "    'feature': [feature_names[i] for i in top5_idx],\n",
    "    'mean_abs_shap': mean_abs_shap[top5_idx]\n",
    "}).to_csv(drivers_fp, index=False)\n",
    "print('Saved top 5 drivers to', drivers_fp)\n",
    "\n",
    "# List output files\n",
    "print('\\nSaved files:')\n",
    "for p in sorted(OUTPUT_DIR.glob('*')):\n",
    "    print('-', p)\n",
    "\n",
    "# Final notes\n",
    "display(HTML(\"<h4>Run the batch explainability script:</h4><pre>python scripts/explain_shap.py --data data/processed/Fraud_Data_processed.csv --output outputs/explainability</pre>\"))\n",
    "display(HTML(\"<p>Report file: <code>docs/TASK_3_SHAP.md</code></p>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ad687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12) Recommendations and interpretation (markdown)\n",
    "\n",
    "HTML('''\n",
    "<h3>Interpretation & Business Recommendations</h3>\n",
    "<ul>\n",
    "<li><b>Top drivers:</b> The top features by mean(|SHAP|) indicate the variables that most strongly push predictions toward fraud vs. legit.</li>\n",
    "<li><b>Recommendation 1:</b> Transactions with high positive SHAP contributions from <i>ip_risk_score</i> or <i>device_is_new</i> should receive additional verification (e.g., 2FA) before approval.</li>\n",
    "<li><b>Recommendation 2:</b> Flag transactions occurring within a short time since signup (high <i>time_since_signup_h</i> or low hours) combined with high amount for manual review.</li>\n",
    "<li><b>Recommendation 3:</b> Use SHAP-informed thresholds to add targeted friction (step-up authentication) only for high-risk patterns to minimize false positives and customer friction.</li>\n",
    "</ul>\n",
    "''')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (waksvenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
